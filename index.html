<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="Css/vars1.css">
  <link rel="stylesheet" href="Css/style1.css">
  
  <style>
   a,
   button,
   input,
   select,
   h1,
   h2,
   h3,
   h4,
   h5,
   * {
       box-sizing: border-box;
       margin: 0;
       padding: 0;
       border: none;
       text-decoration: none;
       background: none;
   
       -webkit-font-smoothing: antialiased;
   }
   
   menu, ol, ul {
       list-style-type: none;
       margin: 0;
       padding: 0;
   }
   </style>
  <title>Document</title>
</head>
<body> 
<div class="wrapper">
<div class="landing-tab">
  <img class="image-9" src="Pictures/image-90.png" />
  <div class="what-is">WHAT IS</div>
  <div class="deepfake">DEEPFAKE?</div>
  <div
    class="deepfake-refers-to-the-use-of-deep-learning-and-fake-techniques-to-create-hyper-realistic-videos-of-individuals-appearing-to-say-or-do-things-that-never-occurred-it-is-a-synthetic-approach-for-replacing-a-person-in-an-existing-image-or-video-with-someone-else-s-characteristic-or-likeness-by-relying-on-machine-learning-algorithms-particularly-generative-adversarial-networks-ga-ns-seow-et-al-2022-westerlund-2019-when-employed-maliciously-deepfakes-can-have-a-negative-impact-on-political-and-social-dynamics-such-as-eroding-trust-in-institutions-harming-the-reputation-of-notable-persons-and-influencing-public-opinion-seow-et-al-2022-deep-fakes-can-also-be-lip-syncing-or-puppeteers-depending-on-how-the-material-is-generated-using-artificial-intelligence-deep-fakes-with-lip-sync-are-videos-in-which-the-mouth-motions-match-the-soundtrack-ahmed-et-al-2022-furthermore-puppet-master-deep-fakes-are-videos-of-puppets-monitoring-the-face-mask-motions-actions-and-head-movements-of-a-grand-in-front-of-a-photographic-camera-deepfake-technologies-frequently-require-a-large-amount-of-image-and-video-data-to-train-the-design-of-recognizable-picture-realistic-images-and-videos-ahmed-et-al-2022"
  >
    Deepfake refers to the use of “deep learning” and “fake” techniques to
    create hyper-realistic videos of individuals appearing to say or do things
    that never occurred. It is a synthetic approach for replacing a person in an
    existing image or video with someone else&#039;s characteristic or likeness
    by relying on machine learning algorithms, particularly Generative
    Adversarial Networks (GANs) (Seow et al., 2022; Westerlund, 2019).
    <br />
    <br />
    When employed maliciously, deepfakes can have a negative impact on political
    and social dynamics, such as eroding trust in institutions, harming the
    reputation of notable persons, and influencing public opinion (Seow et al.,
    2022). Deep fakes can also be lip-syncing or puppeteers, depending on how
    the material is generated using artificial intelligence. Deep fakes with lip
    sync are videos in which the mouth motions match the soundtrack (Ahmed et
    al., 2022). Furthermore, Puppet-master deep fakes are videos of puppets
    monitoring the face mask motions, actions, and head movements of a grand in
    front of a photographic camera, Deepfake technologies frequently require a
    large amount of image and video data to train the design of recognizable
    picture-realistic images and videos. (Ahmed et al., 2022). 
  </div>
  <div
    class="sources-seow-et-al-2022-https-www-sciencedirect-com-science-article-abs-pii-s-0925231222012334-westerlund-2019-https-timreview-ca-article-1282-ahmed-et-al-2022-https-ieeexplore-ieee-org-abstract-document-9799858"
  >
    <span>
      <span
        class="sources-seow-et-al-2022-https-www-sciencedirect-com-science-article-abs-pii-s-0925231222012334-westerlund-2019-https-timreview-ca-article-1282-ahmed-et-al-2022-https-ieeexplore-ieee-org-abstract-document-9799858-span"
      >
        Sources :
        <br />
        Seow et al. (2022) :
      </span>
      <span
        class="sources-seow-et-al-2022-https-www-sciencedirect-com-science-article-abs-pii-s-0925231222012334-westerlund-2019-https-timreview-ca-article-1282-ahmed-et-al-2022-https-ieeexplore-ieee-org-abstract-document-9799858-span2"
      >
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231222012334" style="color:#06172f" target="_blank">Seow, J. W., Lim, M. K., Phan, C. W., & Liu, K. (2022, October 3). A comprehensive overview of Deepfake: Generation, detection, datasets, and opportunities. Science Direct. https://www.sciencedirect.com/science/article/abs/pii/S0925231222012334 </a>
        <br />
      </span>
      <span
        class="sources-seow-et-al-2022-https-www-sciencedirect-com-science-article-abs-pii-s-0925231222012334-westerlund-2019-https-timreview-ca-article-1282-ahmed-et-al-2022-https-ieeexplore-ieee-org-abstract-document-9799858-span3"
      >
        Westerlund (2019) : <a href="https://timreview.ca/article/1282" style="color:#06172f" target="_blank">https://timreview.ca/article/1282</a>
        <br />
        Ahmed et al. (2022) :
      </span>
      <span
        class="sources-seow-et-al-2022-https-www-sciencedirect-com-science-article-abs-pii-s-0925231222012334-westerlund-2019-https-timreview-ca-article-1282-ahmed-et-al-2022-https-ieeexplore-ieee-org-abstract-document-9799858-span4"
      >
        <a href="https://ieeexplore.ieee.org/abstract/document/9799858" style="color:#06172f" target="_blank">S. R. Ahmed, E. Sonuç, M. R. Ahmed and A. D. Duru, "Analysis Survey on Deepfake detection and Recognition with Convolutional Neural Networks," 2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA), Ankara, Turkey, 2022, pp. 1-7, doi: 10.1109/HORA55278.2022.9799858. </a>
      </span>
      <span
        class="sources-seow-et-al-2022-https-www-sciencedirect-com-science-article-abs-pii-s-0925231222012334-westerlund-2019-https-timreview-ca-article-1282-ahmed-et-al-2022-https-ieeexplore-ieee-org-abstract-document-9799858-span5"
      >
        <br />
      </span>
    </span>
  </div>
  <img
    class="deepfake-ethique-removebg-preview-1"
    src="Pictures/deepfake-ethique-removebg-preview-10.png"
  />
  <img class="rectangle-12" src="Pictures/rectangle-120.svg" />
  <div class="rectangle-26"></div>
  <div class="how-it-started">How It Started</div>
  <div class="line-10"></div>
  <div
    class="the-term-came-to-be-used-for-synthetic-media-in-2017-when-a-reddit-moderator-created-a-subreddit-called-deepfakes-and-began-posting-videos-that-used-face-swapping-technology-to-insert-celebrities-likenesses-into-existing-pornographic-videos-payne-2024-however-the-concept-of-deepfakes-or-deepfaking-can-be-traced-back-to-efforts-starting-in-the-1990-s-when-researchers-used-cgi-in-attempts-to-create-realistic-images-of-humans-the-technology-gained-traction-in-the-2010-s-when-the-availability-of-large-datasets-developments-in-machine-learning-and-the-power-of-new-computing-resources-led-to-major-advances-in-the-field-the-open-source-deepfake-creation-tools-have-been-tested-and-refined-by-legions-of-hobbyists-who-have-utilized-these-tools-for-purposes-of-benign-entertainment-memes-swapping-out-actors-faces-in-classic-movies-and-more-sinister-appalling-goals-like-the-creation-of-deepfake-pornography-it-was-the-participation-and-driving-interest-of-everyday-users-beginning-in-2017-that-has-brought-the-technology-to-where-it-is-now-regan-2024"
  >
    The term came to be used for synthetic media in 2017 when a Reddit moderator
    created a subreddit called “deepfakes” and began posting videos that used
    face-swapping technology to insert celebrities’ likenesses into existing
    pornographic videos (Payne, 2024). However, the concept of deepfakes (or
    deepfaking) can be traced back to efforts starting in the 1990s, when
    researchers used CGI in attempts to create realistic images of humans. The
    technology gained traction in the 2010s, when the availability of large
    datasets, developments in machine learning, and the power of new computing
    resources led to major advances in the field. The open-source deepfake
    creation tools have been tested and refined by legions of hobbyists, who
    have utilized these tools for purposes of benign entertainment (memes,
    swapping out actors’ faces in classic movies) and more sinister, appalling
    goals, like the creation of deepfake pornography. It was the participation
    and driving interest of everyday users, beginning in 2017, that has brought
    the technology to where it is now. (Regan, 2024).
    <br />
  </div>
  <img class="image-5" src="Pictures/image-50.png" />
  <div class="line-24"></div>
  <div
    class="deepfake-technology-uses-machine-learning-particularly-generative-adversarial-networks-ga-ns-to-create-fake-but-realistic-videos-or-images-the-process-begins-by-training-a-model-with-large-amounts-of-data-such-as-pictures-or-videos-of-a-person-this-helps-the-model-learn-the-person-s-facial-features-expressions-and-movements-once-trained-the-model-can-replace-someone-s-face-in-a-video-or-change-their-expressions-creating-a-new-synthetic-version-of-the-video-yu-et-al-2021-these-deepfake-videos-often-look-very-real-but-they-might-have-subtle-flaws-for-example-the-face-may-not-match-the-body-perfectly-or-there-could-be-unnatural-movements-these-signs-can-sometimes-help-identify-deepfakes-although-the-technology-has-improved-so-much-that-it-s-becoming-harder-to-spot-them-despite-these-advancements-inconsistencies-in-how-the-face-moves-or-interacts-with-the-rest-of-the-body-can-still-give-deepfakes-away-yu-et-al-2021"
  >
    Deepfake technology uses machine learning, particularly Generative
    Adversarial Networks (GANs), to create fake but realistic videos or images.
    The process begins by training a model with large amounts of data, such as
    pictures or videos of a person. This helps the model learn the person’s
    facial features, expressions, and movements. Once trained, the model can
    replace someone’s face in a video or change their expressions, creating a
    new, synthetic version of the video (Yu et al., 2021).
    <br />
    <br />
    These deepfake videos often look very real, but they might have subtle
    flaws. For example, the face may not match the body perfectly, or there
    could be unnatural movements. These signs can sometimes help identify
    deepfakes, although the technology has improved so much that it’s becoming
    harder to spot them. Despite these advancements, inconsistencies in how the
    face moves or interacts with the rest of the body can still give deepfakes
    away (Yu et al., 2021).
    <br />
  </div>
  <div class="how-it-is-made">How It Is Made</div>
  <img class="image-10" src="Pictures/image-100.png" />
  <img class="image-11" src="Pictures/image-110.png" />
  <div class="ellipse-3"></div>
  <div class="ellipse-4"></div>
  <div class="ellipse-5"></div>
  <div class="line-14"></div>
  <div class="line-15"></div>
  <img class="image-13" src="Pictures/image-130.png" />
  <div
    class="the-obvious-reason-for-the-problem-is-that-deepfakes-can-deceive-humans-even-if-viewers-are-not-tricked-by-a-deepfake-they-may-become-unsure-if-their-content-is-authentic-or-not-uncertainty-is-very-different-from-ambivalence-ambivalence-occurs-when-people-are-faced-with-a-decision-on-which-they-have-opposing-views-and-additional-information-only-heightens-the-internalized-conflict-in-contrast-uncertainty-occurs-when-there-is-not-enough-knowledge-to-make-a-decision-and-it-can-be-resolved-by-the-introduction-of-fresh-information-alavrez-brehm-1997-as-cited-in-vaccari-chadwick-2020-according-to-downs-1957-citizens-experience-uncertainty-because-the-costs-for-gaining-precise-information-are-prohibitively-pricey-deepfakes-may-raise-the-price-of-obtaining-reliable-information-resulting-in-greater-uncertainty-thus-we-investigate-whether-deceptive-deepfakes-create-confusion-about-the-information-they-contain"
  >
    The obvious reason for the problem is that deepfakes can deceive humans.
    Even if viewers are not tricked by a deepfake, they may become unsure if
    their content is authentic or not. Uncertainty is very different from
    ambivalence. Ambivalence occurs when people are faced with a decision on
    which they have opposing views, and &quot;additional information only
    heightens the internalized conflict. In contrast, uncertainty occurs when
    there is not enough knowledge to make a decision, and it can be resolved by
    the introduction of fresh information (Alavrez &amp; Brehm, 1997, as cited
    in Vaccari &amp; Chadwick, 2020) . According to Downs (1957), citizens
    experience uncertainty because the costs for gaining precise information are
    prohibitively pricey. Deepfakes may raise the price of obtaining reliable
    information, resulting in greater uncertainty. Thus, we investigate whether
    deceptive deepfakes create confusion about the information they contain.
    <br />
  </div>
  <div
    class="for-more-information-about-the-threats-deepfake-can-impose-click-on-threats"
  >
    <span>
      <span
        class="for-more-information-about-the-threats-deepfake-can-impose-click-on-threats-span"
      >
        For more information about the Threats Deepfake can Impose,
      </span>
      <span
        class="for-more-information-about-the-threats-deepfake-can-impose-click-on-threats-span2"
      >
      <a href="ThreatsTabs.html" style="color:#06172f" target="_self">Click on  Threats</a>
      </span>
    </span>
  </div>
  <div class="global-urgency">Global Urgency</div>
  <img
    class="global-network-connection-world-map-point-and-line-composition-concept-of-global-business-illustration-vector-1-1"
    src="Pictures/global-network-connection-world-map-point-and-line-composition-concept-of-global-business-illustration-vector-1-10.png"
  />
  <div
    class="source-figure-1-deepfake-detection-techniques-from-maheshwari-paulchamy-2024-study-on-securing-online-integrity-a-hybrid-approach-to-deepfake-detection-and-removal-using-explainable-ai-and-adversarial-robustness-training"
  >
    <a href="https://doi.org/10.1080/00051144.2024.2400640" style="color:#06172f" target="_blank">: Figure 1. Maheshwari, R. U., & Paulchamy, B. (2024). Securing online integrity: a hybrid approach to deepfake detection and removal using Explainable AI and Adversarial Robustness Training. Automatika, 65(4), 1517–1532. https://doi.org/10.1080/00051144.2024.2400640 
    </a>
    <br />
  </div>
  <img class="rectangle-18" src="Pictures/rectangle-180.svg" />
  <div class="the-world-of-deepfake">The World of Deepfake</div>
  <img class="defaketicon-tab-1" src="Pictures/defaketicon-tab-10.png" />
  <div class="line-31"></div>
 <a href="VideoTab.html" class="videos">Demonstrations </a>
 <a href="ThreatsTabs.html" class="threats-recommendations">Threats &amp; Recommendations</a>
 <a href="index.html" class="home">Home</a>
 <a href="About Us.html" class="about-us">About Us</a>
<div class="payne-2024-https-www-britannica-com-technology-deepfake">
  Payne (2024) : <a href="https://www.britannica.com/technology/deepfake" style="color:#f4f4f4" target="_blank">Payne, & Laura. (2025, March 14). Deepfake | History & Facts. Encyclopedia Britannica. https://www.britannica.com/technology/deepfake
  </a>
</div>
<div class="sources">Sources:</div>
<div
  class="regan-2024-https-www-realitydefender-com-blog-history-of-deepfakes"
>
  Regan (2024) : <a href="https://www.realitydefender.com/blog/history-of-deepfakes" style="color:#f4f4f4" target="_blank">Regan, G. (2021, June 1). A Brief History of Deepfakes. Reality Defender. https://www.realitydefender.com/blog/history-of-deepfakes
  </a>
</div>
<div
    class="source-yu-et-al-2021-https-ietresearch-onlinelibrary-wiley-com-doi-full-10-1049-bme-2-12031"
  >
    <span>
      <span
        class="source-yu-et-al-2021-https-ietresearch-onlinelibrary-wiley-com-doi-full-10-1049-bme-2-12031-span"
      >
        Source :
        <br />
        Yu et al. (2021) :
        <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/bme2.12031" style= "color:#06172f" target="_blank">Yu, P., Xia, Z., Fei, J., & Lu, Y. (2021). A survey on deepfake video detection. IET Biometrics, 10(6), 607–624. https://doi.org/10.1049/bme2.12031 
        </a>
      </span>
      <span
        class="source-yu-et-al-2021-https-ietresearch-onlinelibrary-wiley-com-doi-full-10-1049-bme-2-12031-span2"
      >
        <br />
      </span>
      <span
        class="source-yu-et-al-2021-https-ietresearch-onlinelibrary-wiley-com-doi-full-10-1049-bme-2-12031-span3"
      ></span>
    </span>
  </div>
  <div
    class="source-vaccari-chadwick-2020-https-journals-sagepub-com-doi-10-1177-2056305120903408-bibr-18-2056305120903408-downs-1957-also-cited-in-vaccari-chadwick-2020"
  >
    <span>
      <span
        class="source-vaccari-chadwick-2020-https-journals-sagepub-com-doi-10-1177-2056305120903408-bibr-18-2056305120903408-downs-1957-also-cited-in-vaccari-chadwick-2020-span"
      >
        Source :
        <br />
        Vaccari &amp; Chadwick (2020) :
        <a href="https://journals.sagepub.com/doi/10.1177/2056305120903408#bibr18-2056305120903408" style="color:#06172f" target="_blank">Vaccari, C., & Chadwick, A. (2020). Deepfakes and Disinformation: Exploring the impact of synthetic political video on deception, uncertainty, and trust in news. Social Media + Society, 6(1). https://doi.org/10.1177/2056305120903408 
        </a>
        <br />
        Downs (1957) : Downs A. (1957). An economic theory of democracy. Harper.


        also cited in Vaccari &amp; Chadwick (2020)
      </span>
      <span
        class="source-vaccari-chadwick-2020-https-journals-sagepub-com-doi-10-1177-2056305120903408-bibr-18-2056305120903408-downs-1957-also-cited-in-vaccari-chadwick-2020-span2"
      >
        <br />
      </span>
      <span
        class="source-vaccari-chadwick-2020-https-journals-sagepub-com-doi-10-1177-2056305120903408-bibr-18-2056305120903408-downs-1957-also-cited-in-vaccari-chadwick-2020-span3"
      ></span>
    </span>
</div>
</body>

