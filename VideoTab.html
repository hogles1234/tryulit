<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="Css/vars2.css">
  <link rel="stylesheet" href="Css/style2.css">
  
  
  <style>
    #contactInfo {
      color: #06172f;
  font-family: var(
    --var-sds-typography-body-font-family,
    "Inter-Regular",
    sans-serif
  );
  font-size: 30px;
  line-height: 100%;
  font-weight: var(--var-sds-typography-body-font-weight-regular, 400);
  width: 1117px;
  height: 100px;
  position: absolute;
  left: 2px;
  top: 1930px;
  display: flex;
  align-items: center;
  justify-content: center;
  text-align: center;
  }
  #email {
      color: #06172f;
      text-decoration: underline;
  }

#playButton {
    opacity: 0.5;
    cursor: not-allowed;
    pointer-events: none;
    text-decoration: none;
    font-size: 36px;
    background-color: gray;
    padding: 0px 10px;
    border-radius: 6px;
    display: inline-block;
    margin: 20px auto;
    text-align: center;
  
    position: absolute;
    left: 620px;
    top: 4300px;
}

.video-container {
    margin-bottom: 40px;
    text-align: center;
}
   a,
   button,
   input,
   select,
   h1,
   h2,
   h3,
   h4,
   h5,
   * {
       box-sizing: border-box;
       margin: 0;
       padding: 0;
       border: none;
       text-decoration: none;
       background: none;
   
       -webkit-font-smoothing: antialiased;
   }
   
   menu, ol, ul {
       list-style-type: none;
       margin: 0;
       padding: 0;
   }
   </style>
  <title>Document</title>
</head>
<body>
<div class="wrapper"> 
<div class="video-tab">
  <img class="video-tab-rectangle" src="Pictures/video-tab-rectangle0.svg" />
  <div class="rectangle-47"></div>
  <div class="rectangle-48"></div>
  <div class="rectangle-49"></div>
  <div class="rectangle-50"></div>
  <div class="frame-32"></div>
  <div class="rectangle-36"></div>
  <div
    class="length-3-minutes-and-38-seconds-this-video-by-the-new-york-times-illustrates-the-growing-threat-of-deepfakes-ai-generated-videos-that-manipulate-faces-and-voices-making-it-increasingly-impossible-to-trust-visual-content-the-implications-of-deepfakes-are-profound-as-they-contribute-to-the-spread-of-misinformation-undermine-media-credibility-and-pose-risks-to-national-security-and-elections-the-rise-of-deepfakes-along-with-simpler-manipulations-like-shallowfakes-videos-altered-using-basic-editing-techniques-such-as-speeding-up-slowing-down-or-omitting-context-challenges-the-public-s-ability-to-discern-truth-from-falsehood-raising-concerns-about-the-future-of-digital-media-and-its-impact-on-society"
  >
    <span>
      <span
        class="length-3-minutes-and-38-seconds-this-video-by-the-new-york-times-illustrates-the-growing-threat-of-deepfakes-ai-generated-videos-that-manipulate-faces-and-voices-making-it-increasingly-impossible-to-trust-visual-content-the-implications-of-deepfakes-are-profound-as-they-contribute-to-the-spread-of-misinformation-undermine-media-credibility-and-pose-risks-to-national-security-and-elections-the-rise-of-deepfakes-along-with-simpler-manipulations-like-shallowfakes-videos-altered-using-basic-editing-techniques-such-as-speeding-up-slowing-down-or-omitting-context-challenges-the-public-s-ability-to-discern-truth-from-falsehood-raising-concerns-about-the-future-of-digital-media-and-its-impact-on-society-span"
      >
        <br />
        <br />
        Length - 3 minutes and 38 seconds
        <br />
      </span>
      <ul
        class="length-3-minutes-and-38-seconds-this-video-by-the-new-york-times-illustrates-the-growing-threat-of-deepfakes-ai-generated-videos-that-manipulate-faces-and-voices-making-it-increasingly-impossible-to-trust-visual-content-the-implications-of-deepfakes-are-profound-as-they-contribute-to-the-spread-of-misinformation-undermine-media-credibility-and-pose-risks-to-national-security-and-elections-the-rise-of-deepfakes-along-with-simpler-manipulations-like-shallowfakes-videos-altered-using-basic-editing-techniques-such-as-speeding-up-slowing-down-or-omitting-context-challenges-the-public-s-ability-to-discern-truth-from-falsehood-raising-concerns-about-the-future-of-digital-media-and-its-impact-on-society-span2"
      >
        <li>
          This video by The New York Times illustrates the growing threat of
          deepfakes, AI-generated videos that manipulate faces and voices,
          making it increasingly impossible to trust visual content. The
          implications of deepfakes are profound, as they contribute to the
          spread of misinformation, undermine media credibility, and pose risks
          to national security and elections. The rise of deepfakes, along with
          simpler manipulations like shallowfakes, videos altered using basic
          editing techniques such as speeding up, slowing down, or omitting
          context, challenges the publicâ€™s ability to discern truth from
          falsehood, raising concerns about the future of digital media and its
          impact on society.
        </li>
      </ul>
    </span>
  </div>
  <div
    class="uploaded-by-the-new-york-times-on-august-15-2019-website-https-www-nytimes-com-2019-08-14-opinion-deepfakes-adele-disinformation-html"
  >
    <span>
      <span
        class="uploaded-by-the-new-york-times-on-august-15-2019-website-https-www-nytimes-com-2019-08-14-opinion-deepfakes-adele-disinformation-html-span"
      >
        Uploaded By The New York Times on August 15, 2019
        <br />
        Website :
      </span>
      <span
        class="uploaded-by-the-new-york-times-on-august-15-2019-website-https-www-nytimes-com-2019-08-14-opinion-deepfakes-adele-disinformation-html-span2"
      >
        <a href="https://www.nytimes.com/2019/08/14/opinion/deepfakes-adele-disinformation.html" style="color: #06172f" target="_blank">
          https://www.nytimes.com/2019/08/14/opinion/deepfakes-adele-disinformation.html
        </a>
      </span>
    </span>
  </div>
  <div class="deepfakes-is-this-video-even-real-i-nyt-opinion">
    Deepfakes: Is This Video Even Real? I NYT Opinion
  </div>
  <div
    class="length-5-minutes-and-7-seconds-this-video-features-dr-hany-farid-a-professor-at-uc-berkeley-discussing-what-deepfakes-are-their-potential-dangers-and-strategies-to-mitigate-associated-risks-it-s-a-concise-introduction-to-the-subject-highlighting-the-challenges-deepfakes-pose-to-information-security"
  >
    <span>
      <span
        class="length-5-minutes-and-7-seconds-this-video-features-dr-hany-farid-a-professor-at-uc-berkeley-discussing-what-deepfakes-are-their-potential-dangers-and-strategies-to-mitigate-associated-risks-it-s-a-concise-introduction-to-the-subject-highlighting-the-challenges-deepfakes-pose-to-information-security-span"
      >
        <br />
        <br />
        Length - 5 minutes and 7 seconds
        <br />
      </span>
      <ul
        class="length-5-minutes-and-7-seconds-this-video-features-dr-hany-farid-a-professor-at-uc-berkeley-discussing-what-deepfakes-are-their-potential-dangers-and-strategies-to-mitigate-associated-risks-it-s-a-concise-introduction-to-the-subject-highlighting-the-challenges-deepfakes-pose-to-information-security-span2"
      >
        <li>
          This video features Dr. Hany Farid, a professor at UC Berkeley,
          discussing what deepfakes are, their potential dangers, and strategies
          to mitigate associated risks. It&#039;s a concise introduction to the
          subject, highlighting the challenges deepfakes pose to information
          security.
        </li>
      </ul>
    </span>
  </div>
  <div
    class="uploaded-by-uc-berkeley-center-for-long-term-cybersecurity-on-april-1-2021-website-https-cltc-berkeley-edu-publication-what-so-what-now-what-episode-3-a-video-on-deepfakes-featuring-prof-hany-farid"
  >
    <span>
      <span
        class="uploaded-by-uc-berkeley-center-for-long-term-cybersecurity-on-april-1-2021-website-https-cltc-berkeley-edu-publication-what-so-what-now-what-episode-3-a-video-on-deepfakes-featuring-prof-hany-farid-span"
      >
        Uploaded By UC Berkeley Center for Long-Term Cybersecurity on April 1,
        2021
        <br />
        Website:
      </span>
      <span
        class="uploaded-by-uc-berkeley-center-for-long-term-cybersecurity-on-april-1-2021-website-https-cltc-berkeley-edu-publication-what-so-what-now-what-episode-3-a-video-on-deepfakes-featuring-prof-hany-farid-span2"
      >
        <a href="https://cltc.berkeley.edu/publication/what-so-what-now-what-episode-3-a-video-on-deepfakes-featuring-prof-hany-farid/" style="color: #06172f" target="_blank">
          https://cltc.berkeley.edu/publication/what-so-what-now-what-episode-3-a-video-on-deepfakes-featuring-prof-hany-farid/
        </a>
      </span>
      <span
        class="uploaded-by-uc-berkeley-center-for-long-term-cybersecurity-on-april-1-2021-website-https-cltc-berkeley-edu-publication-what-so-what-now-what-episode-3-a-video-on-deepfakes-featuring-prof-hany-farid-span3"
      >
        <br />
      </span>
    </span>
  </div>
  <div class="deepfakes-what-so-what-now-what">
    Deepfakes: What? So What? Now What?
  </div>
  <div
    class="length-7-minutes-and-56-seconds-in-this-video-sam-gregory-program-director-at-the-human-rights-nonprofit-witness-talks-with-wired-senior-writer-tom-simonite-about-the-implications-of-deepfake-videos-and-how-society-can-adjust-to-this-emerging-technology-the-discussion-provides-valuable-insights-into-the-ethical-and-societal-impacts-of-deepfakes"
  >
    <span>
      <span
        class="length-7-minutes-and-56-seconds-in-this-video-sam-gregory-program-director-at-the-human-rights-nonprofit-witness-talks-with-wired-senior-writer-tom-simonite-about-the-implications-of-deepfake-videos-and-how-society-can-adjust-to-this-emerging-technology-the-discussion-provides-valuable-insights-into-the-ethical-and-societal-impacts-of-deepfakes-span"
      >
        <br />
        <br />
        Length - 7 minutes and 56 seconds
        <br />
      </span>
      <ul
        class="length-7-minutes-and-56-seconds-in-this-video-sam-gregory-program-director-at-the-human-rights-nonprofit-witness-talks-with-wired-senior-writer-tom-simonite-about-the-implications-of-deepfake-videos-and-how-society-can-adjust-to-this-emerging-technology-the-discussion-provides-valuable-insights-into-the-ethical-and-societal-impacts-of-deepfakes-span2"
      >
        <li>
          In this video, Sam Gregory, program director at the human rights
          nonprofit WITNESS, talks with WIRED senior writer Tom Simonite about
          the implications of deepfake videos and how society can adjust to this
          emerging technology. The discussion provides valuable insights into
          the ethical and societal impacts of deepfakes.
        </li>
      </ul>
    </span>
  </div>
  <div
    class="uploaded-by-wired-on-october-5-2019-website-https-www-wired-com-video-watch-researcher-explains-deepfake-videos"
  >
    <span>
      <span
        class="uploaded-by-wired-on-october-5-2019-website-https-www-wired-com-video-watch-researcher-explains-deepfake-videos-span"
      >
        Uploaded By WIRED on October 5, 2019
        <br />
        Website:
      </span>
      <span
        class="uploaded-by-wired-on-october-5-2019-website-https-www-wired-com-video-watch-researcher-explains-deepfake-videos-span2"
      >
        <a href="https://www.wired.com/video/watch/researcher-explains-deepfake-videos" style="color: #06172f" target="_blank">
          https://www.wired.com/video/watch/researcher-explains-deepfake-videos
        </a>
      </span>
    </span>
  </div>
  <div class="researcher-explains-deepfake-videos-wired">
    Researcher Explains Deepfake Videos | WIRED
  </div>
  <img class="rectangle-25" src="Pictures/rectangle-250.svg" />
  <div class="rectangle-19"></div>
  <div class="rectangle-46"></div>
  <div class="line-7"></div>
  <div class="line-8"></div>
  <div class="line-9"></div>
  <div class="line-11"></div>
  <div class="line-12"></div>
  <div class="line-16"></div>
  <div class="videos-about-deepfake">Videos About Deepfake</div>
  <img class="_1-1" src="Pictures/_1-10.png" />
  <div
    class="these-videos-offer-an-in-depth-look-at-the-world-of-deepfakes-with-a-total-watch-time-of-just-over-43-minutes-together-they-explain-how-deepfakes-are-made-why-they-re-so-convincing-and-the-impact-they-re-already-having-on-our-lives-the-new-york-times-highlights-how-this-technology-can-fuel-misinformation-and-shake-public-trust-dr-hany-farid-from-berkeley-breaks-down-the-security-risks-in-simple-terms-while-sam-gregory-from-witness-shares-powerful-insights-on-how-society-can-adapt-to-this-new-reality-vox-focuses-on-the-devastating-personal-consequences-of-deepfake-misuse-especially-for-women-and-tom-graham-s-ted-talk-dives-into-the-fine-line-between-creative-innovation-and-harmful-misuse-al-jazeera-s-start-here-episode-offers-a-broad-overview-from-entertaining-uses-to-darker-threats-like-fraud-and-harassment-altogether-these-videos-help-explain-why-deepfakes-matter-and-how-important-it-is-to-be-aware-of-this-technology-not-just-to-protect-ourselves-but-to-shape-a-digital-world-where-truth-can-still-be-trusted"
  >
    These videos offer an in-depth look at the world of deepfakes, with a total
    watch time of just over 43 minutes. Together, they explain how deepfakes are
    made, why theyâ€™re so convincing, and the impact theyâ€™re already having on
    our lives. The New York Times highlights how this technology can fuel
    misinformation and shake public trust. Dr. Hany Farid from Berkeley breaks
    down the security risks in simple terms, while Sam Gregory from WITNESS
    shares powerful insights on how society can adapt to this new reality. VOX
    focuses on the devastating personal consequences of deepfake misuse,
    especially for women, and Tom Grahamâ€™s TED Talk dives into the fine line
    between creative innovation and harmful misuse. Al Jazeera&#039;s Start Here
    episode offers a broad overview, from entertaining uses to darker threats
    like fraud and harassment. Altogether, these videos help explain why
    deepfakes matter and how important it is to be aware of this technology not
    just to protect ourselves, but to shape a digital world where truth can
    still be trusted.
    <br />
  </div>
  <div class="total-watch-time-43-minutes-and-2-seconds">
    <span>
      <span class="total-watch-time-43-minutes-and-2-seconds-span">
        Total Watch Time
      </span>
      <span class="total-watch-time-43-minutes-and-2-seconds-span2"></span>
      <span class="total-watch-time-43-minutes-and-2-seconds-span3">:</span>
      <span class="total-watch-time-43-minutes-and-2-seconds-span4">
        43 minutes and 2 seconds
        <br />
      </span>
    </span>
  </div>
  <div class="line-23"></div>
  <div class="test-your-skills">Test Your Skills!</div>
  <div
    class="test-your-skills-by-playing-our-game-detective-deepfake-simply-identify-whether-the-image-shown-is-deepfake-or-real"
  >
    Test your skills by playing our game, Detective Deepfake, simply identify
    whether the image shown is deepfake or real.
    <br> This game is only accessible after you interact with (Click Here to Watch the Video or Play it from the Website)
  </div>
      <div class="frame-323">
    </div>
  <img class="d-5-3" src="Pictures/d-5-30.png" />
  <div class="line-32"></div>
  <a href="VideoTab.html" class="videos">Demonstrations </a>
  <a href="About Us.html" class="about-us">About Us</a>
  <a href="ThreatsTabs.html" class="threats-recommendations">Threats &amp; Recommendations</a>
  <a href="index.html" class="home">Home</a>
  
  <div class="line-33"></div>
  <a id="playButton" class="play" style="opacity: 0.5; cursor: not-allowed; pointer-events: none;">Play!</a>
  <div class="video-container">
  <iframe id="video1" class="youtube-embed1" src="https://www.youtube.com/embed/1OqFY_2JE1c" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <div class="video-container">
  <iframe id="video2" class="youtube-embed2"  src="https://www.youtube.com/embed/d8HhNgEKNAk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <div class="video-container">
  <iframe id="video3" class="youtube-embed3" src="https://www.youtube.com/embed/u2lX70U7N0c" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <div
    class="length-6-minutes-and-30-seconds-this-vox-video-highlights-how-the-most-immediate-threat-of-deepfakes-lies-not-in-political-misinformation-but-in-more-personal-and-societal-dangers-such-as-non-consensual-explicit-videos-fraud-and-harassment-the-video-underscores-the-devastating-effects-deepfakes-can-have-on-individuals-especially-women-who-often-become-victims-of-such-exploitation-it-provides-a-clear-accessible-breakdown-of-the-current-state-of-deepfake-technology-and-its-rapid-advancement-as-well-as-the-insufficient-legal-and-technological-safeguards-against-its-misuse-the-content-stresses-the-need-for-increased-awareness-and-robust-protective-measures-emphasizing-that-the-most-urgent-concerns-of-deepfakes-are-deeply-personal-and-already-affecting-lives"
  >
    <span>
      <span
        class="length-6-minutes-and-30-seconds-this-vox-video-highlights-how-the-most-immediate-threat-of-deepfakes-lies-not-in-political-misinformation-but-in-more-personal-and-societal-dangers-such-as-non-consensual-explicit-videos-fraud-and-harassment-the-video-underscores-the-devastating-effects-deepfakes-can-have-on-individuals-especially-women-who-often-become-victims-of-such-exploitation-it-provides-a-clear-accessible-breakdown-of-the-current-state-of-deepfake-technology-and-its-rapid-advancement-as-well-as-the-insufficient-legal-and-technological-safeguards-against-its-misuse-the-content-stresses-the-need-for-increased-awareness-and-robust-protective-measures-emphasizing-that-the-most-urgent-concerns-of-deepfakes-are-deeply-personal-and-already-affecting-lives-span"
      >
        <br />
        <br />
        Length - 6 minutes and 30 seconds
        <br />
      </span>
      <ul
        class="length-6-minutes-and-30-seconds-this-vox-video-highlights-how-the-most-immediate-threat-of-deepfakes-lies-not-in-political-misinformation-but-in-more-personal-and-societal-dangers-such-as-non-consensual-explicit-videos-fraud-and-harassment-the-video-underscores-the-devastating-effects-deepfakes-can-have-on-individuals-especially-women-who-often-become-victims-of-such-exploitation-it-provides-a-clear-accessible-breakdown-of-the-current-state-of-deepfake-technology-and-its-rapid-advancement-as-well-as-the-insufficient-legal-and-technological-safeguards-against-its-misuse-the-content-stresses-the-need-for-increased-awareness-and-robust-protective-measures-emphasizing-that-the-most-urgent-concerns-of-deepfakes-are-deeply-personal-and-already-affecting-lives-span2"
      >
        <li>
          This VOX video highlights how the most immediate threat of deepfakes
          lies not in political misinformation but in more personal and societal
          dangers, such as non-consensual explicit videos, fraud, and
          harassment. The video underscores the devastating effects deepfakes
          can have on individuals, especially women, who often become victims of
          such exploitation. It provides a clear, accessible breakdown of the
          current state of deepfake technology and its rapid advancement, as
          well as the insufficient legal and technological safeguards against
          its misuse. The content stresses the need for increased awareness and
          robust protective measures, emphasizing that the most urgent concerns
          of deepfakes are deeply personal and already affecting lives.
        </li>
      </ul>
    </span>
  </div>
  <div class="uploaded-by-vox-on-june-8-2020">
    Uploaded By Vox on June 8, 2020
    <br />
  </div>
  <div class="the-most-urgent-threat-of-deepfakes-isn-t-politics">
    The Most Urgent Threat of Deepfakes isnâ€™t Politics
  </div>
  <div class="video-container">
  <iframe id="video4" class="youtube-embed4" src="https://www.youtube.com/embed/hHHCrf2-x6w" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <div
    class="length-13-minutes-and-6-seconds-in-this-ted-talk-video-tom-graham-ceo-of-a-digital-identity-company-explores-the-dual-edged-nature-of-deepfake-technology-he-discusses-how-deepfakes-have-revolutionized-creative-industries-allowing-for-unprecedented-forms-of-digital-storytelling-virtual-performances-and-immersive-content-creation-however-he-warns-that-the-same-technology-that-fuels-innovation-can-also-be-weaponized-for-misinformation-fraud-and-personal-harm-graham-emphasizes-the-need-to-balance-creativity-with-responsibility-advocating-for-stronger-safeguards-regulations-and-personal-digital-protections-to-ensure-that-advancements-in-ai-benefit-society-without-enabling-exploitation-this-talk-provides-a-nuanced-perspective-on-the-future-of-synthetic-media-and-its-ethical-implications"
  >
    <span>
      <span
        class="length-13-minutes-and-6-seconds-in-this-ted-talk-video-tom-graham-ceo-of-a-digital-identity-company-explores-the-dual-edged-nature-of-deepfake-technology-he-discusses-how-deepfakes-have-revolutionized-creative-industries-allowing-for-unprecedented-forms-of-digital-storytelling-virtual-performances-and-immersive-content-creation-however-he-warns-that-the-same-technology-that-fuels-innovation-can-also-be-weaponized-for-misinformation-fraud-and-personal-harm-graham-emphasizes-the-need-to-balance-creativity-with-responsibility-advocating-for-stronger-safeguards-regulations-and-personal-digital-protections-to-ensure-that-advancements-in-ai-benefit-society-without-enabling-exploitation-this-talk-provides-a-nuanced-perspective-on-the-future-of-synthetic-media-and-its-ethical-implications-span"
      >
        <br />
        <br />
        Length - 13 minutes and 6 seconds
        <br />
      </span>
      <ul
        class="length-13-minutes-and-6-seconds-in-this-ted-talk-video-tom-graham-ceo-of-a-digital-identity-company-explores-the-dual-edged-nature-of-deepfake-technology-he-discusses-how-deepfakes-have-revolutionized-creative-industries-allowing-for-unprecedented-forms-of-digital-storytelling-virtual-performances-and-immersive-content-creation-however-he-warns-that-the-same-technology-that-fuels-innovation-can-also-be-weaponized-for-misinformation-fraud-and-personal-harm-graham-emphasizes-the-need-to-balance-creativity-with-responsibility-advocating-for-stronger-safeguards-regulations-and-personal-digital-protections-to-ensure-that-advancements-in-ai-benefit-society-without-enabling-exploitation-this-talk-provides-a-nuanced-perspective-on-the-future-of-synthetic-media-and-its-ethical-implications-span2"
      >
        <li>
          In this TED talk video, Tom Graham, CEO of a digital identity company,
          explores the dual-edged nature of deepfake technology. He discusses
          how deepfakes have revolutionized creative industries, allowing for
          unprecedented forms of digital storytelling, virtual performances, and
          immersive content creation. However, he warns that the same technology
          that fuels innovation can also be weaponized for misinformation,
          fraud, and personal harm. Graham emphasizes the need to balance
          creativity with responsibility, advocating for stronger safeguards,
          regulations, and personal digital protections to ensure that
          advancements in AI benefit society without enabling exploitation. This
          talk provides a nuanced perspective on the future of synthetic media
          and its ethical implications.
        </li>
      </ul>
    </span>
  </div>
  <div class="uploaded-by-ted-on-may-19-2023">
    Uploaded By TED on May 19, 2023
    <br />
  </div>
  <div
    class="length-7-minutes-and-45-seconds-this-al-jazeera-english-episode-of-start-here-provides-an-in-depth-explanation-of-deepfakes-from-how-they-are-created-using-artificial-intelligence-to-the-ethical-and-societal-dilemmas-they-pose-the-video-outlines-both-the-potential-harmless-uses-of-deepfakes-such-as-entertainment-and-satire-and-the-darker-implications-including-non-consensual-content-political-disinformation-and-financial-fraud-it-features-expert-commentary-on-how-deepfakes-can-erode-trust-in-digital-content-and-highlights-the-difficulty-of-distinguishing-between-authentic-and-synthetic-media-the-episode-stresses-the-urgent-need-for-public-awareness-regulations-and-technical-countermeasures-to-mitigate-the-risks-posed-by-deepfake-technology-in-our-increasingly-digital-world"
  >
    <span>
      <span
        class="length-7-minutes-and-45-seconds-this-al-jazeera-english-episode-of-start-here-provides-an-in-depth-explanation-of-deepfakes-from-how-they-are-created-using-artificial-intelligence-to-the-ethical-and-societal-dilemmas-they-pose-the-video-outlines-both-the-potential-harmless-uses-of-deepfakes-such-as-entertainment-and-satire-and-the-darker-implications-including-non-consensual-content-political-disinformation-and-financial-fraud-it-features-expert-commentary-on-how-deepfakes-can-erode-trust-in-digital-content-and-highlights-the-difficulty-of-distinguishing-between-authentic-and-synthetic-media-the-episode-stresses-the-urgent-need-for-public-awareness-regulations-and-technical-countermeasures-to-mitigate-the-risks-posed-by-deepfake-technology-in-our-increasingly-digital-world-span"
      >
        <br />
        <br />
        Length - 7 minutes and 45 seconds
        <br />
      </span>
      <ul
        class="length-7-minutes-and-45-seconds-this-al-jazeera-english-episode-of-start-here-provides-an-in-depth-explanation-of-deepfakes-from-how-they-are-created-using-artificial-intelligence-to-the-ethical-and-societal-dilemmas-they-pose-the-video-outlines-both-the-potential-harmless-uses-of-deepfakes-such-as-entertainment-and-satire-and-the-darker-implications-including-non-consensual-content-political-disinformation-and-financial-fraud-it-features-expert-commentary-on-how-deepfakes-can-erode-trust-in-digital-content-and-highlights-the-difficulty-of-distinguishing-between-authentic-and-synthetic-media-the-episode-stresses-the-urgent-need-for-public-awareness-regulations-and-technical-countermeasures-to-mitigate-the-risks-posed-by-deepfake-technology-in-our-increasingly-digital-world-span2"
      >
        <li>
          This Al Jazeera English episode of Start Here provides an in-depth
          explanation of deepfakes, from how they are created using artificial
          intelligence to the ethical and societal dilemmas they pose. The video
          outlines both the potential harmless uses of deepfakes, such as
          entertainment and satire, and the darker implications, including
          non-consensual content, political disinformation, and financial fraud.
          It features expert commentary on how deepfakes can erode trust in
          digital content and highlights the difficulty of distinguishing
          between authentic and synthetic media. The episode stresses the urgent
          need for public awareness, regulations, and technical countermeasures
          to mitigate the risks posed by deepfake technology in our increasingly
          digital world.
        </li>
      </ul>
    </span>
  </div>
  <div class="uploaded-by-al-jazeera-english-on-june-21-2021">
    Uploaded By Al Jazeera English on June 21, 2021
    <br />
  </div>
  <div class="what-are-deepfakes-and-are-they-dangerous-start-here">
    What are Deepfakes and are They Dangerous?
    <br />
    | Start Here
  </div>
  <div
    class="the-incredible-creativity-of-deepfakes-and-the-worrying-future-of-ai-tom-graham-ted"
  >
    The Incredible Creativity of Deepfakes â€” and the Worrying Future of AI
    <br />
    | Tom Graham | TED
  </div>
  <div class="video-container">
  <iframe id="video5" class="youtube-embed5" src="https://www.youtube.com/embed/SHSmo72oVao" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <div class="video-container">
  <iframe id="video6" class="youtube-embed6" src="https://www.youtube.com/embed/pkF3m5wVUYI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  <div class="click-here-to-watch-the-video-or-play-it-from-the-website">
    <a href="https://www.youtube.com/watch?v=pkF3m5wVUYI&t=215s" class="video-link" style="color: #06172f" target="_blank">
      Click Here to Watch The Video or Play it from the Website
    </a>
  </div>
  <div class="click-here-to-watch-the-video-or-play-it-from-the-website2">
    <a href="https://www.youtube.com/watch?v=SHSmo72oVao" class="video-link" style="color: #06172f" target="_blank">
      Click Here to Watch The Video or Play it from the Website
    </a>
  </div>
  <div class="click-here-to-watch-the-video-or-play-it-from-the-website3">
    <a href="https://www.youtube.com/watch?v=1OqFY_2JE1c" class="video-link" style="color: #06172f" target="_blank">
      Click Here to Watch The Video or Play it from the Website
    </a>
  </div>
  <div class="click-here-to-watch-the-video-or-play-it-from-the-website4">
    <a href="https://www.youtube.com/watch?v=d8HhNgEKNAk" class="video-link" style="color: #06172f" target="_blank">
      Click Here to Watch The Video or Play it from the Website </a>
  </div>
  <div class="click-here-to-watch-the-video-or-play-it-from-the-website5">
    <a href="https://www.youtube.com/watch?v=u2lX70U7N0c" class="video-link" style="color: #06172f" target="_blank">
      Click Here to Watch The Video or Play it from the Website </a>
  </div>
  <div class="click-here-to-watch-the-video-or-play-it-from-the-website6">
    <a href="https://www.youtube.com/watch?v=hHHCrf2-x6w" class="video-link" style="color: #06172f" target="_blank">
      Click Here to Watch The Video or Play it from the Website </a>

      <script>
        document.addEventListener("DOMContentLoaded", function () {
            let playButton = document.getElementById("playButton");
            let videoLinks = document.querySelectorAll(".video-link");
            let hasInteracted = false;
            let players = {}; // Store YouTube player instances
        
            function enablePlayButton() {
                if (!hasInteracted) {
                    hasInteracted = true;
                    playButton.style.opacity = "1";
                    playButton.style.cursor = "pointer";
                    playButton.style.pointerEvents = "auto"; // Ensure it's clickable
                    playButton.style.backgroundColor = "#28a745"; // Green when enabled
                    playButton.href = "Game.html"; // Enable game link
                    console.log("âœ… Play button enabled!");
                }
            }
        
            // Enable button if any external YouTube link is clicked
            videoLinks.forEach(link => {
                link.addEventListener("click", enablePlayButton);
            });
        
            // Load YouTube API only if it's not already loaded
            function loadYouTubeAPI() {
                if (typeof YT === "undefined" || typeof YT.Player === "undefined") {
                    let script = document.createElement("script");
                    script.src = "https://www.youtube.com/iframe_api";
                    script.async = true;
                    script.defer = true;
                    document.head.appendChild(script);
                } else {
                    onYouTubeIframeAPIReady(); // API is already available, initialize directly
                }
            }
        
            // YouTube API Callback Function (Ensures API is Ready)
            window.onYouTubeIframeAPIReady = function () {
                let videoIds = ["video1", "video2", "video3", "video4", "video5", "video6"];
                videoIds.forEach(videoId => {
                    let videoElement = document.getElementById(videoId);
                    if (videoElement) {
                        players[videoId] = new YT.Player(videoId, {
                            events: {
                                'onStateChange': function (event) {
                                    if (event.data === YT.PlayerState.PLAYING) {
                                        console.log(`ðŸŽ¥ ${videoId} is playing.`);
                                        enablePlayButton();
                                    }
                                },
                                'onReady': function () {
                                    console.log(`âœ… ${videoId} is ready.`);
                                }
                            }
                        });
                    } else {
                        console.warn(`âš  Video element not found: ${videoId}`);
                    }
                });
            };
        
            // Wait before loading YouTube API to prevent timing issues
            setTimeout(() => {
                loadYouTubeAPI();
            }, 500);
        });
        </script>
        

      <p id="contactInfo" style="color:#06172f; cursor: pointer;">
        For any inquiries or feedback, Contact: Killua Andrei Nava 
        <span id="email"><br><a href="#" style="color:#06172f" onclick="openMailto(event)">killua.andrei.nava@k12.adamson.edu.ph</a></span>.
    </p>
    
    <script>
        function openMailto(event) {
            event.preventDefault();
    
            const email = "killua.andrei.nava@k12.adamson.edu.ph";
            const subject = encodeURIComponent("Inquiry/Concern Regarding Defaketicon");
            const body = encodeURIComponent("Hello,\n\nI would like to inquire about:\n\n");
    
            const mailtoLink = `mailto:${email}?subject=${subject}&body=${body}`;
    
            
            const newTab = window.open('', '_blank');
    
           
            setTimeout(() => {
                newTab.location.href = mailtoLink;
            }, 500);
        }
    </script>
  </div>
</div> 
</body>